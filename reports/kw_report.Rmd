---
title: "PREDICT 413 Final Project"
author: "Kevin Wong"
date: "November 14, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r dataset, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(caret)
library(Metrics)
library(moments)
library(VIM)
library(h2o)
library(h2oEnsemble)
train <- read.csv("../data/train.csv",stringsAsFactors=FALSE)
test <- read.csv("../data/test.csv",stringsAsFactors=FALSE)
```

### Problem
The problem we are trying to solve here is to build models to predict house prices, given the Ames Housing dataset, with high degree of predictive accuracy. The problem does not call for specific algorithms or techniques to be used. Machine learning is a street brawl.

### Significance
The goal of the problem was to utilize any and all machine learning tools or time series forecasting techniques to make the best possible prediction of house prices. This is an interesting problem because most people will eventually buy/sell a home. This problem allows us, as data scientists, learn more about the housing market and helps with making more informed decisions. 

This project encouraged getting our hands dirty to clean, transform, and engineer features that enabled better predictions. This problem also necessitated learning popular algorithms and tools. The use of Kaggle as a platform for data science competition helped motivate us to keep improving. 

### Data

*Description*  
The Ames Housing dataset was retrieved from https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data. The dataset represents residential properties in Ames, Iowa from 2006 to 2010. There is a train and a test file. The train file has 1460 observations and the test file has 1459 observations. Both datasets contain 79 explanatory variables composed of 46 categorical and 33 continuous variables that describe house features such as neighborhood, square footage, number of full bathrooms, and many more. The train file contains a response variable column, **SalePrice**, which is what we will predict in the test set. There is also a unique identifier for each house sold, but were not used in fitting the models.

*Exploratory Data Analysis*
Below is the plot of the SalePrice. Notice that 

```{r saleprice}
hist(train$SalePrice)
```


```{r}
hist(log(train$SalePrice+1))
```

One can see that the variable is 

Some basic exploration of the data revealed little pattern to go off of. It would appear that the monthly rainfall totals randomly fluctuate. The boxplot gives more insight where May, June, September, and October have the highest average precipitation. Each month has several outliers that might influence model fitting.

*Feature Importance*


*Data Preprocessing*
-combine train and test to normalize factors/cats
-log transform response
-remove correlated, constant or near zero variance variables
-separate num and cat variables, fix skew of numeric and one hot encode cat?
-NA imputation using mean

### Type of Models
The following are five models which were developed to predict house prices. These models were chosen because they showcase varying complexity and also have proven to perform well on many Kaggle problems. 

1. LASSO
The LASSO, also known as Least Absolute Shrinkage and Selection Operator), is a regression model that does variable selection and regularization. The LASSO model uses a parameter that penalizes fitting too many variables. It allows the shrinkage of variable coefficients to 0, which essentially results in those variables having no effect in the model, thereby reducing dimensionality. Since there are quite a few explanatory variables, reducing the number of variables may increase interpretability and prediction accuracy.

2. Random Forest
It is possible that there is some seasonality component to the dataset such as certain months having more or less rainfall than others. The seasonal naïve model uses the value from the same season last year (Hyndman & Athana¬sopou¬los, n.d.). In this case, the seasons are the months. So seasonal naïve forecasting will use last June’s rainfall amount as the rainfall amount for this June’s forecast.

3. GBM
Many forecasting techniques require time series data. However, the multiple linear regression model requires cross sectional data. A benefit to using this model was to make predictions using more than one predictor. It is assumed in this model that the predictors used, year and month, have a linear relationship to the amount of precipitation. The linear regression model tends to be easy to interpret and usually can give relatively good results even when assumptions are violated.

4. Neural Networks
The use of TBATS (Trigonometric Box-Cox ARMA Trend Seasonal) model is an advanced time series forecasting technique that may do quite well when there are multiple seasonal patterns or perhaps complex seasonal patterns (Hyndman, 2015). When we plotted the precipitation time series above, the data points are largely random fluctuations where seasonal or trend patterns, if any, are hard to see. The hope is that this model can give good results and exploit multiple seasonal patterns if they exist.

5. Stacked/Ensemble Model
A more advanced model, the random forest uses multiple decision trees and gives the mean prediction of each tree. This is somewhat of a black box approach as the random forest mechanism is not very clear as it will give results, but have a lack of information such as coefficients. However, the random forest model is a great general purpose algorithm that has potential to make quite accurate forecasts.

### Literature
The following five examples refer to the type of models used in this report that have been applied to similar cases.

*Lasso*
Environmental conditions often can impact respiratory health such as asthma. A group decided to forecast asthma-related admissions in London using daily average weather, air quality, and asthma-related admissions data in 2005-2006. Several models were fit including a model using the 2005 mean value and the seasonal naïve. These models were compared with negative binomial model. A training set of 2005-2006 hospital admissions was used to fit the models and validated on the holdout set from 2006-2007. The mean model was able to outperform the other models when using the RMSE and MASE (Soyiri & Sarran, 2013).

*Random Forest*
Time series sales in the food industry tend to be extremely volatile and skewed so inaccurate forecasts are an often occurrence resulting in food waste and stock outs. Accurate forecasts are necessary in order to properly plan inventory. In a study from the International Journal of Production Economics, hybrid seasonal ARIMA are used and compared against the seasonal naïve benchmark. Examples include using daily sales of bananas as the dependent variable and days, months, holidays, lags, discounts, etc., as the predictors. The models were compared using the RMSE on the test set. In most cases the seasonal naïve benchmark is widely used by retail managers. The seasonal naïve model underperforms with other hybrid approaches both in RMSE and % forecast accuracy (Arunraj & Ahrens, 2015).

*GBM*
Multiple linear regression can be used to model sewer system costs. The cost of the entire sewer system is a function of all the costs from individual systems like manholes and gravity pipes. Each individual cost function is a function of their physical assets and was developed using multiple linear regression where the particular system like manhole is the dependent variable and the independent variables are depth and height of the manhole. As a result, these cost functions produced can inform business decisions around sewer system costs (Marchionni, Lopes, Mamouros, & Covas, 2014).

*Neural Networks*
Hotel revenue management is affected by factors such as daily demand. These are time series type data. In order to make effective decisions around hotel revenue management, accurate daily demand is usually forecasted. Daily demand often displays complex seasonal patterns. A study from the International Journal of Hospitality Management utilizes TBATS to improve accuracy of hotel’s daily forecasts. The TBATS model was applied to daily time series data for each type of hotel room (classic, deluxe, and suites). The model was validated using RMSE and MAPE. The TBATS model performed well with shorter forecast horizons (less than 8 weeks) while naïve approaches were more accurate in the long term (Pereira, 2016).

*Stacked/Ensemble Model*
The H5N1 avian influenza was a hot topic few years back. Understanding disease patterns such as cyclical patterns can help minimize and prevent outbreaks. From the BMC Bioinformatics journal, a random forest model was used on time series data to predict avian flu outbreaks in Egypt. The model was trained on multiple predictors using 1000 trees and sampling 3 variables from each tree. The model was compared with an ARIMA model using MSE. The random forest model outperformed the ARIMA likely due to the lack of linear relationships and ability to predict upward shocks (Kane, Price, Scotch, & Rabinowitz, 2014).

### Formulation
-caret package
-h2o package

The models were implemented first by reading in the dataset using the data.table library. Two versions of the dataset were saved—one as a pure time series for using time series techniques such as forecasting benchmarks and one as a cross sectional dataset for using techniques like linear regression, random forests, and support vector machines.  The cross sectional dataset required slightly more manipulation to extract individual month and year columns.

The complete dataset was split into two separate datasets, train and test. The training set contains the first 80% of the observations, while the test set contains the remaining 20% of observations. The models were fit using the training data. The mean, seasonal naïve, and TBATS models were simply fit using their respective functions (meanf, snaive, and tbats) from the forecast package on the training data. No parameters were adjusted besides the forecasting period. 

The multiple linear regression and random forest were fit using their respective functions (lm and randomForest) on the training data using the year and month variables. The multiple linear regression model did not require any parameter tuning while some parameter tuning was performed for the random forest and support vector machine models. The random forest model was optimized when using 1000 trees and sampling 2 variables from each tree. 

The residuals of the fitted models are examined and assessed for goodness of fit. The forecast accuracy of each model were validated on the test set. Each model was compared on root mean squared error (RMSE).

### Model Performance
The models were assessed by examining the residuals for violations in normality and/or having autocorrelations. Each model performance is compared using the RMSE on the test set.

Model | Log RMSE
-------|----------
Multiple Linear Regression with Stepwise Selection | 0
LASSO | 1
Random Forest | 2
Neural Network | 3
Stacked Ensemble | 4

### Limitations
The multiple linear regression model is a great general purpose algorithm for many problems out there. However, some assumptions must be met such as there is a linear relationship between the response and predictors. It also makes lots of assumptions regarding the residuals to have mean zero, constant variance, and be normally distributed. Generally, violations to these assumptions will not restrict the ability of the model to predict, but can hinder the confidence in those predictions. 


The specific linear regression and random forest models I created require that a dataset have month and year as predictors.

The other models used are restricted to time series data. These techniques have very little parameters to adjust for optimization of the models. These models will not work when run on cross sectional data. Also, these models would not be appropriate for classification problems.

Something to note is that a lot of the performance of these models may depend on the predictors inputted. There may be some additional predictors that can be extracted that may enhance certain models presented here.

### Future Work
The goal in developing these models is to be able to understand and to apply them to other real world datasets. The plan is to further develop these models through hyper-parameterization and running them in distributed computing environment. My hope is to be able to showcase this project and other future similar projects to employers. This project has inspired me to compete in other Kaggle competitions using models developed here. 

### Learning
This project was fairly complex in terms of dealing with many explanatory variables. By no means was this big data, but higher dimension datasets can be difficult to deal with if not prepared appropriately to be fed into machine learning algorithms.

Some of the major takeaways from this project are that there are packages that help automate the modeling process like the *caret* package. This package allows you to utilize grid search and cross validation to select optimal model parameters. This was especially helpful when fine tuning models to make better predictions.

Another nice package/engine is the *h2o* package. It allows you to run machine learning algorithms in-memory in a distributed fashion. So for algorithms like neural networks or random forests, which can take a long time to train, would literally take a few seconds. This allows more iterations and experimentation.

Model complexity does not necessarily lead to better predictions. As mentioned earlier, simpler models like the LASSO, could produce better results than black box methods like neural networks, which did not seem to perform well in this competition.

Lastly, because the dataset contained many variables, it really challenged my skills in R in terms of manipulating data and writing functions more effectively and efficiently.


### References

Hyndman, R. J., & Athana¬sopou¬los, G. (n.d.). 2.3 Some simple forecasting methods. Retrieved 	October 25, 2016, from https://www.otexts.org/fpp/2/3

Hyndman, R. J. (2015). New in forecast 4.0. Retrieved October 25, 2016, from 	http://robjhyndman.com/hyndsight/forecast4/

Soyiri, I. N., Reidpath, D. D., & Sarran, C. (2013). Forecasting asthma-related hospital 	admissions in London using negative binomial models. Chronic Respiratory 	Disease, 10(2), 85-94. doi:10.1177/1479972313482847

Arunraj, N. S., & Ahrens, D. (2015, December). A hybrid seasonal autoregressive integrated 	moving average and quantile regression for daily food sales forecasting. International 	Journal of Production Economics, 170, 321-335. doi:10.1016/j.ijpe.2015.09.039

Marchionni, V., Lopes, N., Mamouros, L., & Covas, D. (2014, August 07). Modelling Sewer 	Systems Costs with Multiple Linear Regression. Water Resources Management, 28(13), 	4415-4431. doi:10.1007/s11269-014-0759-z

Pereira, L. N. (2016, September). An introduction to helpful forecasting methods for hotel r	evenue management. International Journal of Hospitality Management, 58, 13-23. 	doi:10.1016/j.ijhm.2016.07.003

Kane, M. J., Price, N., Scotch, M., & Rabinowitz, P. (2014). Comparison of ARIMA and R	andom Forest time series models for prediction of avian influenza H5N1 outbreaks. BMC 	Bioinformatics, 15(1), 1-9. doi:10.1186/1471-2105-15-276

