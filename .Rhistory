trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
set.seed(123)  # for reproducibility
lasso_mod2 <- train(x=x_train,y=y,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
lasso_mod2
preds <- exp(predict(lasso_mod2,newdata=x_test)) - 1
solution <- data.frame(Id=as.integer(rownames(x_test)),SalePrice=preds)
head(solution)
tail(solution)
write.csv(solution,"lasso2.csv",row.names=FALSE)
?pairs
corr_df <- data.frame(total$X1stFlrSF,total$X2ndFlrSF,total$LowQualFinSF,total$GrLivArea,total$TotFlrSF)
cor(corr_df)
total$AllLivArea <- total$X1stFlrSF+total$X2ndFlrSF+total$LowQualFinSF+total$GrLivArea
rm(list=ls())
memory.size(max=T)
library(doParallel)
library(foreach)
c1=makeCluster(2)
registerDoParallel(c1)
library(ggplot2)
library(dplyr)
library(data.table)
library(caret)
library(moments)
train <- read.csv("data/train.csv",stringsAsFactors=FALSE)
test <- read.csv("data/test.csv",stringsAsFactors=FALSE)
train_eda <- train
total <- rbind(dplyr::select(train,MSSubClass:SaleCondition),
dplyr::select(test,MSSubClass:SaleCondition))
train$SalePrice <- log(train$SalePrice+1)
total$YearMo <- as.numeric(total$YrSold)*12+as.numeric(total$MoSold)
total$TotFlrSF <- as.numeric(total$X1stFlrSF)+as.numeric(total$X2ndFlrSF)
total$AllLivArea <- total$X1stFlrSF+total$X2ndFlrSF+total$LowQualFinSF+total$GrLivArea
feature_classes <- sapply(names(total),function(x){class(total[[x]])})
numeric_vars <- names(feature_classes[feature_classes!="character"])
skewed_vars <- sapply(numeric_vars,function(x){skewness(total[[x]],na.rm=TRUE)})
skewed_vars <- skewed_vars[skewed_vars>0.75]
for(x in names(skewed_vars)) {
total[[x]] <- log(total[[x]]+1)
}
cat_vars <- names(feature_classes[feature_classes=="character"])
dummies <- dummyVars(~.,total[cat_vars])
cat_encode <- predict(dummies,total[cat_vars])
cat_encode[is.na(cat_encode)] <- 0
numeric_df <- total[numeric_vars]
for(x in numeric_vars){
mean_value <- mean(train[[x]],na.rm=TRUE)
total[[x]][is.na(total[[x]])] <- mean_value
}
total <- cbind(total[numeric_vars],cat_encode)
x_train <- total[1:nrow(train),]
x_test <- total[(nrow(train)+1):nrow(total),]
y <- train$SalePrice
corr_df <- data.frame(total$X1stFlrSF,total$X2ndFlrSF,total$LowQualFinSF,total$GrLivArea,total$TotFlrSF,total$AllLivArea)
cor(corr_df)
dropvars <- c("X1stFlrSF","X2ndFlrSF","GrLivArea")
dim(total)
total[,!(names(total)%in%dropvars)]
dim(total)
total <- total[,!(names(total)%in%dropvars)]
dim(total)
tail(str(total))
fitControl <- trainControl(method="repeatedcv",
number=5,
repeats=5,
verboseIter=FALSE)
set.seed(123)  # for reproducibility
lasso_mod2 <- train(x=x_train,y=y,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
lasso_mod2
rm(list=ls())
library(ggplot2)
library(dplyr)
library(data.table)
library(caret)
library(moments)
train <- read.csv("data/train.csv",stringsAsFactors=FALSE)
test <- read.csv("data/test.csv",stringsAsFactors=FALSE)
memory.size(max=T)
library(doParallel)
library(foreach)
c1=makeCluster(2)
registerDoParallel(c1)
train_eda <- train
total <- rbind(dplyr::select(train,MSSubClass:SaleCondition),
dplyr::select(test,MSSubClass:SaleCondition))
train$SalePrice <- log(train$SalePrice+1)
total$TotFlrSF <- as.numeric(total$X1stFlrSF)+as.numeric(total$X2ndFlrSF)
total$AllLivArea <- total$X1stFlrSF+total$X2ndFlrSF+total$LowQualFinSF+total$GrLivArea
feature_classes <- sapply(names(total),function(x){class(total[[x]])})
numeric_vars <- names(feature_classes[feature_classes!="character"])
skewed_vars <- sapply(numeric_vars,function(x){skewness(total[[x]],na.rm=TRUE)})
skewed_vars <- skewed_vars[skewed_vars>0.75]
for(x in names(skewed_vars)) {
total[[x]] <- log(total[[x]]+1)
}
cat_vars <- names(feature_classes[feature_classes=="character"])
dummies <- dummyVars(~.,total[cat_vars])
cat_encode <- predict(dummies,total[cat_vars])
cat_encode[is.na(cat_encode)] <- 0
numeric_df <- total[numeric_vars]
for(x in numeric_vars){
mean_value <- mean(train[[x]],na.rm=TRUE)
total[[x]][is.na(total[[x]])] <- mean_value
}
total <- cbind(total[numeric_vars],cat_encode)
x_train <- total[1:nrow(train),]
x_test <- total[(nrow(train)+1):nrow(total),]
y <- train$SalePrice
fitControl <- trainControl(method="repeatedcv",
number=5,
repeats=5,
verboseIter=FALSE)
set.seed(123)  # for reproducibility
lasso_mod3 <- train(x=x_train,y=y,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
lasso_mod3
preds <- exp(predict(lasso_mod3,newdata=x_test)) - 1
solution <- data.frame(Id=as.integer(rownames(x_test)),SalePrice=preds)
write.csv(solution,"lasso3.csv",row.names=FALSE)
head(solution)
tail(solutio)
tail(solution)
anyNA(train)
anyNA(x_train)
anyNA(x_test)
rm(list=ls())
library(ggplot2)
library(dplyr)
library(data.table)
library(caret)
library(moments)
train <- read.csv("data/train.csv",stringsAsFactors=FALSE)
test <- read.csv("data/test.csv",stringsAsFactors=FALSE)
memory.size(max=T)
library(doParallel)
library(foreach)
c1=makeCluster(2)
registerDoParallel(c1)
train_eda <- train
total <- rbind(dplyr::select(train,MSSubClass:SaleCondition),
dplyr::select(test,MSSubClass:SaleCondition))
train$SalePrice <- log(train$SalePrice+1)
feature_classes <- sapply(names(total),function(x){class(total[[x]])})
numeric_vars <- names(feature_classes[feature_classes!="character"])
skewed_vars <- sapply(numeric_vars,function(x){skewness(total[[x]],na.rm=TRUE)})
skewed_vars <- skewed_vars[skewed_vars>0.75]
for(x in names(skewed_vars)) {
total[[x]] <- log(total[[x]]+1)
}
cat_vars <- names(feature_classes[feature_classes=="character"])
dummies <- dummyVars(~.,total[cat_vars])
cat_encode <- predict(dummies,total[cat_vars])
cat_encode[is.na(cat_encode)] <- 0
numeric_df <- total[numeric_vars]
for(x in numeric_vars){
median_value <- median(train[[x]],na.rm=TRUE)
total[[x]][is.na(total[[x]])] <- median_value
}
total <- cbind(total[numeric_vars],cat_encode)
x_train <- total[1:nrow(train),]
x_test <- total[(nrow(train)+1):nrow(total),]
y <- train$SalePrice
anyNA(total)
fitControl <- trainControl(method="repeatedcv",
number=5,
repeats=5,
verboseIter=FALSE)
set.seed(123)  # for reproducibility
lasso_mod4 <- train(x=x_train,y=y,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
lasso_mod4
preds <- exp(predict(lasso_mod4,newdata=x_test)) - 1
solution <- data.frame(Id=as.integer(rownames(x_test)),SalePrice=preds)
write.csv(solution,"lasso4.csv",row.names=FALSE)
head(solution)
tail(solution)
rm(list=ls())
library(ggplot2)
library(dplyr)
library(data.table)
library(caret)
library(moments)
memory.size(max=T)
library(doParallel)
library(foreach)
c1=makeCluster(2)
registerDoParallel(c1)
train_eda <- train
total <- rbind(dplyr::select(train,MSSubClass:SaleCondition),
dplyr::select(test,MSSubClass:SaleCondition))
train$SalePrice <- log(train$SalePrice+1)
rm(list=ls())
library(ggplot2)
library(dplyr)
library(data.table)
library(caret)
library(moments)
train <- read.csv("data/train.csv",stringsAsFactors=FALSE)
test <- read.csv("data/test.csv",stringsAsFactors=FALSE)
memory.size(max=T)
library(doParallel)
library(foreach)
c1=makeCluster(2)
registerDoParallel(c1)
train_eda <- train
total <- rbind(dplyr::select(train,MSSubClass:SaleCondition),
dplyr::select(test,MSSubClass:SaleCondition))
train$SalePrice <- log(train$SalePrice+1)
feature_classes <- sapply(names(total),function(x){class(total[[x]])})
numeric_vars <- names(feature_classes[feature_classes!="character"])
skewed_vars <- sapply(numeric_vars,function(x){skewness(total[[x]],na.rm=TRUE)})
skewed_vars <- skewed_vars[skewed_vars>0.75]
for(x in names(skewed_vars)) {
total[[x]] <- log(total[[x]]+1)
}
cat_vars <- names(feature_classes[feature_classes=="character"])
dummies <- dummyVars(~.,total[cat_vars])
cat_encode <- predict(dummies,total[cat_vars])
cat_encode[is.na(cat_encode)] <- 0
?mice
library(mice)
anyNA(total)
total[is.na(total)]
anyNA(total[cat_vars])
summary(total)
length(total[numeric_vars])
length(total[cat_encode])
total <- cbind(total[numeric_vars],cat_encode)
anyNA(total[1:36])
total[1:36]
total[,1:36]
total[1:36,]
length(total)
anyNA(total[cat_encode])
total(cat_encode)
total[cat_encode]
head(total)
length(numeric_vars)
anyNA(total[c(37:)])
dim(total)
anyNA(total[c(37:288)])
anyNA(total[c(1:36)])
total[c(1:36)]
total[c(1:37)]
anyNA(total[c(1:36)])
anyNA(total[c(37:288)])
imp <- mice(total, m=1, method='cart', seed=123, maxit=1)
total <- complete(imp)
anyNA(total)
fitControl <- trainControl(method="repeatedcv",
number=5,
repeats=5,
verboseIter=FALSE)
set.seed(123)  # for reproducibility
lasso_mod4 <- train(x=x_train,y=y,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
x_train <- total[1:nrow(train),]
nrow(train)
x_test <- total[(nrow(train)+1):nrow(total),]
y <- train$SalePrice
set.seed(123)  # for reproducibility
lasso_mod4 <- train(x=x_train,y=y,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
lasso_mod4
fitControl
set.seed(123)
svm2 <- train(x=x_train,y=y,
method = "svmLinear2",
trControl = fitControl,
verbose = FALSE)
svm2
log(1.423)
log(1.423?lm
?lm
head(x_train)
dim(x_train)
mylm=lm(x=x_train,y=y)
total
y
totaltrain <- cbind(y,x_train)
anyNA(totaltrain)
head(totaltrain)
dim(totaltrain)
mylm=lm(y~., data=totaltrain)
mystep1=stepAIC(mylm, direction="both")
library(MASS)
mystep1=stepAIC(mylm, direction="both")
total["RoofMatl"]
total[,"RoofMatl"]
colnames(total)
train["RoofMatl"]
summary(train["RoofMatl"])
train_eda
summary(train_eda)
summary(as.factor(train_eda$RoofMatl))
nearZeroVar(as.factor(train_eda$RoofMatl))
nearZeroVar(as.factor(train_eda$RoofMatl),saveMetrics = T)
coef(lasso_mod4)
lasso_mod4
attributes(lasso_mod4)
lasso_mod4$modelInfo
attributes(lasso_mod4)
lasso_mod4$finalModel
lasso_mod4$results
rm(list=ls())
train <- read.csv("data/train.csv",stringsAsFactors=FALSE)
test <- read.csv("data/test.csv",stringsAsFactors=FALSE)
train2 <- read.csv("data/train.csv",stringsAsFactors=FALSE)
test2 <- read.csv("data/test.csv",stringsAsFactors=FALSE)
train2 <- read.csv("data/train.csv",stringsAsFactors=TRUE)
test2 <- read.csv("data/test.csv",stringsAsFactors=TRUE)
library(ggplot2)
library(dplyr)
library(data.table)
library(caret)
library(moments)
library(VIM)
library(mice)
memory.size(max=T)
library(doParallel)
library(foreach)
c1=makeCluster(2)
registerDoParallel(c1)
train_eda <- train
total <- rbind(dplyr::select(train,MSSubClass:SaleCondition),
dplyr::select(test,MSSubClass:SaleCondition))
total2 <- rbind(dplyr::select(train2,MSSubClass:SaleCondition),
dplyr::select(test2,MSSubClass:SaleCondition))
str(total2)
nearZeroVar(total2,saveMetrics = T)
nearZeroVar(total,saveMetrics = T)
library(data.table)
total <- as.data.table(total)
removeVar <- c("Street","Alley","LandContour","Utilities","LandSlope","Condition2","RoofMatl","BsmtCond","BsmtFinType2","BsmtFinSF2",
"Heating","LowQualFinSF","KitchenAbvGr","Functional","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","PoolArea","PoolQC",
"MiscFeature","MiscVal")
total[,(removeVar):=NULL,with=FALSE]
dim(total)
train$SalePrice <- log(train$SalePrice+1)
feature_classes <- sapply(names(total),function(x){class(total[[x]])})
numeric_vars <- names(feature_classes[feature_classes!="character"])
skewed_vars <- sapply(numeric_vars,function(x){skewness(total[[x]],na.rm=TRUE)})
skewed_vars <- skewed_vars[skewed_vars>0.75]
for(x in names(skewed_vars)) {
total[[x]] <- log(total[[x]]+1)
}
cat_vars <- names(feature_classes[feature_classes=="character"])
dummies <- dummyVars(~.,total[cat_vars])
total <- rbind(dplyr::select(train,MSSubClass:SaleCondition),
dplyr::select(test,MSSubClass:SaleCondition))
dim(total)
total[,removeVar]
class(total)
total[,-removeVar]
total[,-c(removeVar)]
total <- total[,!(names(total) %in% removeVar)]
dim(total)
rm(list=ls())
train <- read.csv("data/train.csv",stringsAsFactors=FALSE)
test <- read.csv("data/test.csv",stringsAsFactors=FALSE)
library(ggplot2)
library(dplyr)
library(data.table)
library(caret)
library(moments)
library(VIM)
library(mice)
library(rpart)
# Setup environment to maximize parellel computing
memory.size(max=T)
library(doParallel)
library(foreach)
c1=makeCluster(2)
registerDoParallel(c1)
train_eda <- train
total <- rbind(dplyr::select(train,MSSubClass:SaleCondition),
dplyr::select(test,MSSubClass:SaleCondition))
removeVar <- c("Street","Alley","LandContour","Utilities","LandSlope","Condition2","RoofMatl","BsmtCond","BsmtFinType2","BsmtFinSF2",
"Heating","LowQualFinSF","KitchenAbvGr","Functional","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","PoolArea","PoolQC",
"MiscFeature","MiscVal")
total <- total[,!(names(total) %in% removeVar)]
train$SalePrice <- log(train$SalePrice+1)
feature_classes <- sapply(names(total),function(x){class(total[[x]])})
numeric_vars <- names(feature_classes[feature_classes!="character"])
skewed_vars <- sapply(numeric_vars,function(x){skewness(total[[x]],na.rm=TRUE)})
skewed_vars <- skewed_vars[skewed_vars>0.75]
for(x in names(skewed_vars)) {
total[[x]] <- log(total[[x]]+1)
}
cat_vars <- names(feature_classes[feature_classes=="character"])
dummies <- dummyVars(~.,total[cat_vars])
cat_encode <- predict(dummies,total[cat_vars])
cat_encode[is.na(cat_encode)] <- 0
numeric_df <- total[numeric_vars]
for(x in numeric_vars){
mean_value <- mean(train[[x]],na.rm=TRUE)
total[[x]][is.na(total[[x]])] <- mean_value
}
total <- cbind(total[numeric_vars],cat_encode)
x_train <- total[1:nrow(train),]
x_test <- total[(nrow(train)+1):nrow(total),]
y <- train$SalePrice
fitControl <- trainControl(method="repeatedcv",
number=5,
repeats=5,
verboseIter=FALSE)
set.seed(123)  # for reproducibility
lasso_mod5 <- train(x=x_train,y=y,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
lasso_mod5
set.seed(123)  # for reproducibility
lasso_mod5 <- train(x=x_train,y=y,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.0005),
0.00075,0.0005,0.0001)))
lasso_mod5
set.seed(123)  # for reproducibility
ridge1 <- train(x=x_train,y=y,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=c(seq(1,0,-0.01)),  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
ridge1
attributes(ridge1)
ridge1$results[,3]
min(ridge1$results[,3])
lasso_mod5
library(xgboost)
set.seed(123)
xgb2 <- train(x = x_train, y = y,
method = "xgbTree",
trControl = fitControl,
#tuneGrid=tuneGrid,
verbose = FALSE)
xgb2
set.seed(123)
nn1 <- train(x=x_train,y=y,
method = "neuralnet",
trControl = fitControl,
#tuneGrid=tuneGrid,
verbose = FALSE)
nn1
methods(train)
method(train)
?train
set.seed(123)
rf2 <- train(x=x_train,y=y, trControl=fitControl, method="rf")
rf2
preds <- exp(predict(rf2,newdata=x_test)) - 1
solution <- data.frame(Id=as.integer(rownames(x_test)),SalePrice=preds)
head(solution)
tail(solution)
?randomForest
write.csv(solution,"rf2.csv",row.names=FALSE)
colnames(train)
colnames(x_train)
rf2
rm(list=ls())
